defaultAirflowRepository: apache/airflow
defaultAirflowTag: "3.1.6"
airflowVersion: "3.1.6"

executor: "LocalExecutor"

postgresql:
  enabled: false

data:
  metadataSecretName: airflow-db-secret

redis:
  enabled: false

statsd:
  enabled: false

config:
  # Hier überschreiben wir die Defaults aus dem Chart:
  core:
    load_examples: "False"
    # DIESER WERT EXISTIERT IM DEFAULT NICHT, IST ABER FÜR AF3 PFLICHT:
    internal_api_url: "http://airflow-api-server:8080"
    
  api:
    # Erlaubt dem Task SDK, sich am API-Server anzumelden
    auth_backends: "airflow.api.auth.backend.session,airflow.api.auth.backend.basic_auth"

ingress:
  enabled: true
  apiServer:
    enabled: true
    ingressClassName: nginx
    annotations:
      cert-manager.io/cluster-issuer: letsencrypt-prod
      nginx.ingress.kubernetes.io/backend-protocol: "HTTP"
    hosts:
      - name: airflow.group-jofz.dski23a.timebertt.dev
        tls:
          enabled: true
          secretName: airflow-tls
    path: "/"
    pathType: "ImplementationSpecific"

# images:
#   airflow:
#     repository: ghcr.io/tobiasfuhge/airflow-spark-custom
#     tag: "1.0"
#     pullPolicy: Always

dags:
  gitSync:
    enabled: true
    repo: https://github.com/tobiasfuhge/ml-pipeline.git
    branch: main
    subPath: "dags"

createUserJob:
  useHelmHooks: false
  applyCustomEnv: false

migrateDatabaseJob:
  useHelmHooks: false
  applyCustomEnv: false

workers:
  persistence:
    enabled: false

triggerer:
  persistence:
    enabled: false